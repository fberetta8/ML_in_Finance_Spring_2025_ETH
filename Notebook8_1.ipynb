{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fberetta8/ML_in_Finance_Spring_2025_ETH/blob/main/Notebook8_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KBuJrh3V0iN"
      },
      "source": [
        "\n",
        "# Pricing in SABR model\n",
        "The **SABR model** (Stochastic Alpha, Beta, Rho) is a stochastic volatility model commonly used in the pricing of derivatives, especially interest rate options and swaptions.\n",
        "\n",
        "It models the forward price $F_t$ and its volatility $\\sigma_t$ using the following system of SDEs:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "dF_t &= \\sigma_t F_t^{\\beta} dW_t, \\\\\n",
        "d\\sigma_t &= \\nu \\sigma_t dB_t, \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "with:\n",
        "\n",
        "- $\\beta \\in [0, 1]$: controls the dependence of volatility on the price (elasticity).\n",
        "- $\\nu > 0$: volatility of volatility.\n",
        "- $\\rho \\in [-1, 1]$: correlation between the two Brownian motions $W_t$ and $B_t$.\n",
        "\n",
        "The initial volatility is denoted $\\alpha = \\sigma_0$. We aim to learn the map\n",
        "\n",
        "$$\n",
        "(\\alpha, \\beta, \\rho, \\nu) \\rightarrow \\text{price}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hagan Approximation\n",
        "\n",
        "Since the SABR model does **not** admit a closed-form solution for option prices, practitioners typically use the **Hagan et al. approximation** to compute **implied volatilities** under SABR. This implied volatility can then be inserted into the **Black-Scholes formula** to compute prices. In this notebook, we rely on this approximation to simulate data and train a machine learning model to learn the price function."
      ],
      "metadata": {
        "id": "Ui1rePLtTwXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxK_i4WeWsSj",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m7GDQ_YX5yK"
      },
      "outputs": [],
      "source": [
        "# Implied Volatility Formula\n",
        "def sabr_implied_vol(F, K, T, alpha, beta, rho, nu):\n",
        "    if F == K:\n",
        "        term1 = (1 + ((1 - beta)**2 / 24) * (alpha**2 / F**(2 - 2*beta))\n",
        "                 + (rho * beta * nu * alpha) / (4 * F**(1 - beta))\n",
        "                 + (nu**2 * (2 - 3 * rho**2)) / 24) * T\n",
        "        return alpha / (F**(1 - beta)) * (1 + term1)\n",
        "\n",
        "    log_FK = np.log(F / K)\n",
        "    z = (nu / alpha) * (F * K)**((1 - beta)/2) * log_FK\n",
        "    x_z = np.log((np.sqrt(1 - 2 * rho * z + z**2) + z - rho) / (1 - rho))\n",
        "    FK_beta = (F * K)**((1 - beta)/2)\n",
        "\n",
        "    term1 = (1 + ((1 - beta)**2 / 24) * (log_FK)**2\n",
        "             + ((1 - beta)**4 / 1920) * (log_FK)**4)\n",
        "    term2 = (1 + ((1 - beta)**2 / 24) * (alpha**2 / FK_beta**2)\n",
        "             + (rho * beta * nu * alpha) / (4 * FK_beta)\n",
        "             + (nu**2 * (2 - 3 * rho**2)) / 24) * T\n",
        "\n",
        "    return (alpha / (FK_beta * term1)) * (z / x_z) * (1 + term2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Given the implied volatility, we compute the price of a European\n",
        "# call option using the Black-Scholes formula.\n",
        "\n",
        "def black_scholes_call(F, K, T, sigma):\n",
        "    d1 = (np.log(F / K) + 0.5 * sigma**2 * T) / (sigma * np.sqrt(T))\n",
        "    d2 = d1 - sigma * np.sqrt(T)\n",
        "    return F * norm.cdf(d1) - K * norm.cdf(d2)"
      ],
      "metadata": {
        "id": "ZsnkUTPxgMis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data\n",
        "\n",
        "def generate_data(n_samples=10000, F=100.0, K=100.0, T=1.0):\n",
        "    alphas = np.random.uniform(0.05, 0.5, n_samples)\n",
        "    betas = np.random.uniform(0.0, 1.0, n_samples)\n",
        "    rhos = np.random.uniform(-0.99, 0.99, n_samples)\n",
        "    nus = np.random.uniform(0.1, 1.0, n_samples)\n",
        "\n",
        "    X = np.stack([alphas, betas, rhos, nus], axis=1)\n",
        "    y = []\n",
        "\n",
        "    for alpha, beta, rho, nu in X:\n",
        "        sigma = sabr_implied_vol(F, K, T, alpha, beta, rho, nu)\n",
        "        price = black_scholes_call(F, K, T, sigma)\n",
        "        y.append(price)\n",
        "\n",
        "    return X, np.array(y)"
      ],
      "metadata": {
        "id": "fBRunM5z2DTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data and divide train/test set\n",
        "\n",
        "X, y = generate_data()\n",
        "y_log = np.log1p(y) # We apply log-transform, it helps the fit\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
        "    X_scaled, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train_log, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test_log, dtype=torch.float32).view(-1, 1)"
      ],
      "metadata": {
        "id": "8MGac4Zhx26V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Build a model based on a feed-forward NN. Train it on the train set and\n",
        "#       make predictions over the test set."
      ],
      "metadata": {
        "id": "d-Z--3DK5E5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Visualize the predicted prices vs the one computed via Hagan approx\n",
        "#       (assumed to be the \"real\" prices), over the test set."
      ],
      "metadata": {
        "id": "ex7oohyR5T7K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeviNfa2rDFn11DPF1k9QB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}